用户权限：
root用户（如果安装系统时候已经创建了其他用户并使用非root用户登录，则需要先su root）


sudo useradd -m -g dcyw 组 新建用户名
sudo passwd 新建用户名


vim /etc/sudoers
# 默认存在: root用户 具备所有的权限
root    ALL=(ALL)       ALL

# 授予 lisi 用户 所有的权限
dcyw    ALL=(ALL)       ALL

su 新建用户名
权限问题：
chmod -R 755 文件|目录
chattr -i 文件名(当无法删除某个文件时，需要权限)
每台虚拟机修改对应主机名重启后永久生效
sudo vi /etc/sysconfig/network
HOSTNAME=dcywz1

hostnamectl set-hostname 命名
sudo hostnamectl set-hostname dcyw1

每台虚拟机设置ip和域名映射
sudo vim /etc/hosts
192.168.88.128 dcyw1 dcyw1.hadoop.com
192.168.88.129 dcyw2 dcyw2.hadoop.com
192.168.88.130 dcyw3 dcyw3.hadoop.com
查看防火墙状态
sudo systemctl status firewalld
关闭防火墙
sudo systemctl stop firewalld
开机不启动防火墙
systemctl disable firewalld

关闭selinux修改selinux的配置文件
sudo vi /etc/selinux/config
SELINUX=disabled
三台机器生成公钥与私钥
ssh-keygen -t rsa

三台机器都要执行以下命令，密钥对可以用复制粘贴的方法
ssh-copy-id dcyw1
ssh-copy-id dcyw2
ssh-copy-id dcyw3
三台机器时钟同步
## 安装
yum install -y ntp

## 启动定时任务
crontab -e
*/1 * * * * /usr/sbin/ntpdate ntp4.aliyun.com;
安装软件--JDK
查看自带JDK
rpm -qa | grep java
卸载自带JDK
sudo rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64
sudo rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64
sudo rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64
sudo rpm -e --nodeps java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64
解压自己的JDK
unzip jdk.zip
vim /~.bash_profile
export JAVA_HOME=/home/dcyw/server/jdk1.8
export PATH=:$JAVA_HOME/bin:$PATH
source .bash_profile
chmod -R 755 jdk目录
java -version
scp /home/dcyw/server/jdk1.8 dcywz2:/home/dcyw/server/
scp /home/dcyw/.bach_profile dcywz2:/home/dcyw/
source .bash_profile
scp /home/dcyw/server/jdk1.8 dcywz3:/home/dcyw/server/
scp /home/dcyw/.bach_profile dcywz3:/home/dcyw/
source .bash_profile
每台机器用jps查询java进程
解压自己的ZK
vim  zoo.cfg
创建一个数据存放路径
mkdir /export/servers/zookeeper-3.4.9/zkdatas
vim  zoo.cfg
dataDir=/export/servers/zookeeper-3.4.9/zkdatas
# 保留多少个快照
autopurge.snapRetainCount=3
# 日志多少小时清理一次
autopurge.purgeInterval=1
# 集群中服务器地址
server.1=dcywz1:2888:3888
server.2=dcywz2:2888:3888
server.3=dcywz3:2888:3888
进入自创的数据目录
vim myid
写入1
scp到每台机器重复之前的操作并更改myid中的数字，依次更改
启动所有机器zookeeper
zookeeper目录下bin目录中./zkServer.sh start  (status)
解压自己的hadoop
cd 到Hadoop目录下/etc/hadoop/
修改IP及数据存放目录地址
修改:
core-site.xml、(改成默认配置)
hdfs-site.xml、（更改路径即可:关注hadoop版本号同步）
hadoop-env.sh、（注释掉classpath，和heapsize）
yarn-site.xml、(改了1个地址)
mapred-env.sh(添加Java地址)
vim slaves （改ip）
node01
node02
node03
添加环境变量
export HADOOP_HOME=/export/servers/hadoop-2.7.5
export PATH=:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
source .bash_profile
分发
scp -r hadoop目录 到dcyw：￥PWD
启动hadoop
启动Hadoop命令：
cd /export/server/hadoop-2.7.5/  进入Hadoop目录
bin/hdfs namenode -format  首次运行的格式化
sbin/start-dfs.sh  启动hdfs  jps :namenode+datanode
sbin/start-yarn.sh  启动yarn  jps: SecondaryNameNode+ResourceManager+nodemanager
sbin/mr-jobhistory-daemon.sh start historyserver  历史job任务 jps: JobHistoryServer
三个端口查看界面
http://192.168.88.163:50070/explorer.html#/ 查看hdfs
http://192.168.88.163:8088/cluster 查看yarn集群
http://192.168.88.163:19888/jobhistory 查看历史完成的Job任务

解压自己的KAFKA
更改Kafka目录下config/server.properties
# 指定broker的id每台机器需不同
broker.id=0
# 指定Kafka监听本机端口
listeners=PLAINTEXT://本机:6667
# 指定Kafka数据的位置
log.dirs=/export/server/kafka_2.12-2.4.1/data
# 配置zk的三个节点
zookeeper.connect=node1.itcast.cn:2181,node2.itcast.cn:2181,node3.itcast.cn:2181
注意：bin/kafka-server-start.sh中关于heap-otps内存的设置（256m,128m）
                                export KAFKA_OPTS=路径设置
每台机器启动
kafka目录下  bin/kafka-server-start.sh config/server.properties
启动命令：
bin/kafka-server-start.sh -daemon config/server.properties

配置卡夫卡一键启动脚本

创建一个目录，vim slave配置文件，用于保存要启动哪几个节点上的kafka
node1.itcast.cn
node2.itcast.cn
node3.itcast.cn
编写start-kafka.sh脚本
vim start-kafka.sh
cat /export/onekey/slave | while read line
do
{
 echo $line
 ssh $line "source /etc/profile;export JMX_PORT=9988;nohup ${KAFKA_HOME}/bin/kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties >/dev/nul* 2>&1 & "
}&
wait
done
给定权限
chmod u+x start-kafka.sh

编写一键启动脚本
vim bigdata
复制以下内容：到文件中
#!/bin/bash
function startZK(){
ZKIP=(dcywz1 dcywz2 dcywz3)
for ip in ${ZKIP[*]};
do
   #登录
   echo -e "\e[1;32m 当前${ip}正在启动zookeep \e[0m"
   ssh ${ip} "source /home/dcyw/.bash_profile;/home/dcyw/server/zookeeper-3.4.14/bin/zkServer.sh start"
   echo -e "\e[1;35m ${ip}启动结束----------\n\n \e[0m"

   `exit`
done;
}

function startkafka(){
/home/dcyw/export/onekey/start-kafka.sh
}

function startHadoop(){
cd /home/dcyw/server/hadoop2.7.3/
sbin/start-all.sh
}



#启动zk集群
startZK;
sleep 5
#启动Kafka集群
startkafka
sleep 5
#启动hadoop集群
startHadoop;

保存退出后执行测试
./bigdata

添加到开机自启文件
sudo vim /etc/rc.d/rc.local
写入
source /home/dcyw/.bash_profile
touch /var/lock/subsys/local
su dcyw -c"/home/dcyw/bigdata"
保存 
给予此文件权限
chmod +x /etc/rc.d/rc.local
完毕！重启服务器！（先重启分支节点，最后重启主节点，保证执行自启脚本时分支节点都在线）










